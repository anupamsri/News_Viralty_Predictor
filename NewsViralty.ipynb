{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BY- ANUPAM SRIVASTAVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newspaper3k in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (0.2.8)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from newspaper3k) (0.35.1)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from newspaper3k) (7.1.1)\n",
      "Requirement already satisfied: PyYAML>=3.11 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from newspaper3k) (5.3.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from newspaper3k) (2.23.0)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from newspaper3k) (2.2.2)\n",
      "Requirement already satisfied: nltk>=3.2.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from newspaper3k) (3.5)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from newspaper3k) (0.0.4)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from newspaper3k) (4.5.0)\n",
      "Requirement already satisfied: tinysegmenter==0.3 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from newspaper3k) (0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from newspaper3k) (2.8.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from newspaper3k) (4.9.0)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from newspaper3k) (5.2.1)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from newspaper3k) (1.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests>=2.10.0->newspaper3k) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests>=2.10.0->newspaper3k) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from requests>=2.10.0->newspaper3k) (2.9)\n",
      "Requirement already satisfied: requests-file>=1.4 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
      "Requirement already satisfied: setuptools in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from tldextract>=2.0.1->newspaper3k) (46.1.3.post20200325)\n",
      "Requirement already satisfied: click in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from nltk>=3.2.1->newspaper3k) (7.1.1)\n",
      "Requirement already satisfied: tqdm in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from nltk>=3.2.1->newspaper3k) (4.45.0)\n",
      "Requirement already satisfied: regex in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from nltk>=3.2.1->newspaper3k) (2020.4.4)\n",
      "Requirement already satisfied: joblib in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from nltk>=3.2.1->newspaper3k) (0.14.1)\n",
      "Requirement already satisfied: six in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.14.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article  \n",
    "import csv\n",
    "from urllib.request import urlopen\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling News from Hindustan Times Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ndtv.com/world-news/\"\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.content, 'html5lib') \n",
    "table = soup.findAll('a', attrs = {'href':re.compile(\"^https://www.ndtv.com/world-news/\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.ndtv.com/world-news/north-korean-leader-kim-jong-uns-train-likely-spotted-in-resort-town-amid-health-rumours-report-2218393?News_Trending', 'https://www.ndtv.com/world-news/coronavirus-pandemic-all-covid19-patients-in-wuhan-discharged-says-china-2218484', 'https://www.ndtv.com/world-news/north-korean-leader-kim-jong-uns-train-likely-spotted-in-resort-town-amid-health-rumours-report-2218393', 'https://www.ndtv.com/world-news/us-president-donald-trump-russias-vladimir-putin-issue-rare-joint-statement-on-cooperation-2218385', 'https://www.ndtv.com/world-news/coronavirus-in-us-not-worth-time-effort-says-donald-trump-on-pressers-after-disinfectant-gaffe-2218362', 'https://www.ndtv.com/world-news/covid-19-death-count-global-coronavirus-death-count-crosses-2-lakhs-who-warns-over-immunity-2218355', 'https://www.ndtv.com/world-news/coronavirus-france-reports-369-new-covid-19-deaths-in-last-24-hours-2218327', 'https://www.ndtv.com/world-news/coronvirus-china-eases-restrictions-on-exports-of-some-covid-19-treatment-products-2218310', 'https://www.ndtv.com/world-news/coronavirus-uk-reports-813-new-covid-19-deaths-count-rises-to-20-319-2218305', 'https://www.ndtv.com/world-news/coronavirus-italy-9-year-old-italian-boy-lupo-daturi-creates-cerba-20-video-game-on-covid-19-2218300', 'https://www.ndtv.com/world-news/coronavirus-ecuador-woman-named-alba-maruri-pronounced-dead-due-to-covid-19-in-hospital-mix-up-wakes-2218291', 'https://www.ndtv.com/world-news/alphabets-sundar-pichais-2019-compensation-worth-281-million-2218184', 'https://www.ndtv.com/world-news/coronavirus-pandemic-no-evidence-that-recovered-covid-19-patients-wont-be-reinfected-who-2218169', 'https://www.ndtv.com/world-news/she-survived-spanish-flu-in-1918-now-at-106-she-beat-covid-19-2218072', 'https://www.ndtv.com/world-news/coronavirus-pandemic-covid19-global-death-count-nears-200-000-says-report-2218050', 'https://www.ndtv.com/world-news/page-2', 'https://www.ndtv.com/world-news/page-3', 'https://www.ndtv.com/world-news/page-4', 'https://www.ndtv.com/world-news/page-5', 'https://www.ndtv.com/world-news/page-6', 'https://www.ndtv.com/world-news/page-7', 'https://www.ndtv.com/world-news/page-8', 'https://www.ndtv.com/world-news/page-9', 'https://www.ndtv.com/world-news/page-10', 'https://www.ndtv.com/world-news/page-14']\n"
     ]
    }
   ],
   "source": [
    "news=[]\n",
    "for row in table: \n",
    "    if row['href'] not in news and not row['href']==\"https://www.ndtv.com/world-news/\":\n",
    "        news.append(row['href'])  \n",
    "print(news)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=[]\n",
    "for i in news:\n",
    "    article = Article(i, language=\"en\")\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    article.nlp()\n",
    "    data={}\n",
    "    data['Title']=article.title\n",
    "    data['Text']=article.text\n",
    "    data['Summary']=article.summary\n",
    "    data['Keywords']=article.keywords\n",
    "    df.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kim Jong Un's Train Likely Spotted In Resort T...</td>\n",
       "      <td>There have been conflicting reports about Kim ...</td>\n",
       "      <td>There have been conflicting reports about Kim ...</td>\n",
       "      <td>[korean, train, north, whereabouts, spotted, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All Coronavirus Patients In Wuhan Have Been Di...</td>\n",
       "      <td>Covid -19 Cases: Wuhan in China had reported 4...</td>\n",
       "      <td>Covid -19 Cases: Wuhan in China had reported 4...</td>\n",
       "      <td>[wuhan, cases, 56, staff, discharged, coronavi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kim Jong Un's Train Likely Spotted In Resort T...</td>\n",
       "      <td>There have been conflicting reports about Kim ...</td>\n",
       "      <td>There have been conflicting reports about Kim ...</td>\n",
       "      <td>[korean, train, north, whereabouts, spotted, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald Trump, Vladimir Putin Issue Rare Joint ...</td>\n",
       "      <td>Donald Trump had hoped to travel to Moscow to ...</td>\n",
       "      <td>Donald Trump had hoped to travel to Moscow to ...</td>\n",
       "      <td>[statement, donald, elbe, river, cooperation, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Not Worth Time And Effort\": Donald Trump On P...</td>\n",
       "      <td>He appeared to confirm media reports that he w...</td>\n",
       "      <td>He appeared to confirm media reports that he w...</td>\n",
       "      <td>[house, donald, effort, coronavirus, worth, tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Kim Jong Un's Train Likely Spotted In Resort T...   \n",
       "1  All Coronavirus Patients In Wuhan Have Been Di...   \n",
       "2  Kim Jong Un's Train Likely Spotted In Resort T...   \n",
       "3  Donald Trump, Vladimir Putin Issue Rare Joint ...   \n",
       "4  \"Not Worth Time And Effort\": Donald Trump On P...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  There have been conflicting reports about Kim ...   \n",
       "1  Covid -19 Cases: Wuhan in China had reported 4...   \n",
       "2  There have been conflicting reports about Kim ...   \n",
       "3  Donald Trump had hoped to travel to Moscow to ...   \n",
       "4  He appeared to confirm media reports that he w...   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  There have been conflicting reports about Kim ...   \n",
       "1  Covid -19 Cases: Wuhan in China had reported 4...   \n",
       "2  There have been conflicting reports about Kim ...   \n",
       "3  Donald Trump had hoped to travel to Moscow to ...   \n",
       "4  He appeared to confirm media reports that he w...   \n",
       "\n",
       "                                            Keywords  \n",
       "0  [korean, train, north, whereabouts, spotted, r...  \n",
       "1  [wuhan, cases, 56, staff, discharged, coronavi...  \n",
       "2  [korean, train, north, whereabouts, spotted, r...  \n",
       "3  [statement, donald, elbe, river, cooperation, ...  \n",
       "4  [house, donald, effort, coronavirus, worth, tr...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.DataFrame(df)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for predicting virality of news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH=\"/resources/NewsVirality/OnlineNewsPopularity.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/resources/NewsVirality'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cols(data):\n",
    "    \"\"\"Clean the column names by stripping and lowercase.\"\"\"\n",
    "    clean_col_map = {x: x.lower().strip() for x in list(data)}\n",
    "    return data.rename(index=str, columns=clean_col_map)\n",
    "\n",
    "def TrainTestSplit(X, Y, R=0, test_size=0.2):\n",
    "    \"\"\"Easy Train Test Split call.\"\"\"\n",
    "    return train_test_split(X, Y, test_size=test_size, random_state=R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
       "      <td>731.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
       "      <td>731.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.540890</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2013/01/07/amazon-instant-...      731.0   \n",
       "1  http://mashable.com/2013/01/07/ap-samsung-spon...      731.0   \n",
       "2  http://mashable.com/2013/01/07/apple-40-billio...      731.0   \n",
       "3  http://mashable.com/2013/01/07/astronaut-notre...      731.0   \n",
       "4   http://mashable.com/2013/01/07/att-u-verse-apps/      731.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0            12.0             219.0         0.663594               1.0   \n",
       "1             9.0             255.0         0.604743               1.0   \n",
       "2             9.0             211.0         0.575130               1.0   \n",
       "3             9.0             531.0         0.503788               1.0   \n",
       "4            13.0            1072.0         0.415646               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
       "0                  0.815385        4.0             2.0       1.0  ...   \n",
       "1                  0.791946        3.0             1.0       1.0  ...   \n",
       "2                  0.663866        3.0             1.0       1.0  ...   \n",
       "3                  0.665635        9.0             0.0       1.0  ...   \n",
       "4                  0.540890       19.0            19.0      20.0  ...   \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.100000                    0.7              -0.350000   \n",
       "1               0.033333                    0.7              -0.118750   \n",
       "2               0.100000                    1.0              -0.466667   \n",
       "3               0.136364                    0.8              -0.369697   \n",
       "4               0.033333                    1.0              -0.220192   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                 -0.600              -0.200000            0.500000   \n",
       "1                 -0.125              -0.100000            0.000000   \n",
       "2                 -0.800              -0.133333            0.000000   \n",
       "3                 -0.600              -0.166667            0.000000   \n",
       "4                 -0.500              -0.050000            0.454545   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                 -0.187500                0.000000   \n",
       "1                  0.000000                0.500000   \n",
       "2                  0.000000                0.500000   \n",
       "3                  0.000000                0.500000   \n",
       "4                  0.136364                0.045455   \n",
       "\n",
       "   abs_title_sentiment_polarity  shares  \n",
       "0                      0.187500     593  \n",
       "1                      0.000000     711  \n",
       "2                      0.000000    1500  \n",
       "3                      0.000000    1200  \n",
       "4                      0.136364     505  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/resources/NewsVirality/OnlineNewsPopularity/OnlineNewsPopularity.csv',sep='\\s*,\\s*')\n",
    "full_data = clean_cols(df)\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(full_data, test_size=0.20, random_state=42)\n",
    "\n",
    "x_train = train_set.drop(['url','shares', 'timedelta', 'lda_00','lda_01','lda_02','lda_03','lda_04','num_self_hrefs', 'kw_min_min', 'kw_max_min', 'kw_avg_min','kw_min_max','kw_max_max','kw_avg_max','kw_min_avg','kw_max_avg','kw_avg_avg','self_reference_min_shares','self_reference_max_shares','self_reference_avg_sharess','rate_positive_words','rate_negative_words','abs_title_subjectivity','abs_title_sentiment_polarity'], axis=1)\n",
    "y_train = train_set['shares']\n",
    "\n",
    "x_test = test_set.drop(['url','shares', 'timedelta', 'num_self_hrefs', 'kw_min_min', 'kw_max_min', 'kw_avg_min','kw_min_max','kw_max_max','kw_avg_max','kw_min_avg','kw_max_avg','kw_avg_avg','self_reference_min_shares','self_reference_max_shares','self_reference_avg_sharess','rate_positive_words','rate_negative_words','abs_title_subjectivity','abs_title_sentiment_polarity'], axis=1)\n",
    "y_test = test_set['shares']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestRegressor(random_state=42)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_res = pd.DataFrame(clf.predict(x_train),list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual shares</th>\n",
       "      <th>Predicted shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16100</td>\n",
       "      <td>11492.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>508</td>\n",
       "      <td>1334.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1300</td>\n",
       "      <td>1280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3100</td>\n",
       "      <td>2940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6900</td>\n",
       "      <td>5960.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual shares  Predicted shares\n",
       "0          16100           11492.9\n",
       "1            508            1334.8\n",
       "2           1300            1280.0\n",
       "3           3100            2940.0\n",
       "4           6900            5960.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_res.reset_index(level=0, inplace=True)\n",
    "rf_res_df = rf_res.rename(index=str, columns={\"index\": \"Actual shares\", 0: \"Predicted shares\"})\n",
    "rf_res_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Crawled News according to Training Set in UCI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "stopwords=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_unique(words):\n",
    "    words=tokenize(words)\n",
    "    no_order = list(set(words))\n",
    "    rate_unique=len(no_order)/len(words)\n",
    "    return rate_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_nonstop(words):\n",
    "    words=tokenize(words)\n",
    "    filtered_sentence = [w for w in words if not w in stopwords]\n",
    "    rate_nonstop=len(filtered_sentence)/len(words)\n",
    "    no_order = list(set(filtered_sentence))\n",
    "    rate_unique_nonstop=len(no_order)/len(words)\n",
    "    return rate_nonstop,rate_unique_nonstop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_token(words):\n",
    "    words=tokenize(words)\n",
    "    length=[]\n",
    "    for i in words:\n",
    "        length.append(len(i))\n",
    "    return np.average(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: click in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from nltk>=3.1->textblob) (7.1.1)\n",
      "Requirement already satisfied: tqdm in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from nltk>=3.1->textblob) (4.45.0)\n",
      "Requirement already satisfied: regex in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from nltk>=3.1->textblob) (2020.4.4)\n",
      "Requirement already satisfied: joblib in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from nltk>=3.1->textblob) (0.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datefinder in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2017.02.08 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from datefinder) (2020.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.4.2 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from datefinder) (2.8.1)\n",
      "Requirement already satisfied: pytz in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from datefinder) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from python-dateutil>=2.4.2->datefinder) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datefinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import datefinder\n",
    "import datetime  \n",
    "from datetime import date \n",
    "def day(article_text):\n",
    "    article=article_text\n",
    "    if len(list(datefinder.find_dates(article)))>0:\n",
    "        date=str(list(datefinder.find_dates(article))[0])\n",
    "        date=date.split()\n",
    "        date=date[0]\n",
    "        year, month, day = date.split('-')\n",
    "        if(int(month)>12 or int(month)<0):\n",
    "            return \"Monday\"\n",
    "        day_name = datetime.date(int(year), int(month), int(day))\n",
    "        return day_name.strftime(\"%A\")\n",
    "    return \"Monday\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text=text\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words=[]\n",
    "neg_words=[]\n",
    "def polar(words):\n",
    "    all_tokens=tokenize(words)\n",
    "    for i in all_tokens:\n",
    "        analysis=TextBlob(i)\n",
    "        polarity=analysis.sentiment.polarity\n",
    "        if polarity>0:\n",
    "            pos_words.append(i)\n",
    "        if polarity<0:\n",
    "            neg_words.append(i)\n",
    "    return pos_words,neg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rates(words):\n",
    "    words=polar(words)\n",
    "    pos=words[0]\n",
    "    neg=words[1]\n",
    "    all_words=words\n",
    "    global_rate_positive_words=(len(pos)/len(all_words))/100\n",
    "    global_rate_negative_words=(len(neg)/len(all_words))/100\n",
    "    pol_pos=[]\n",
    "    pol_neg=[]\n",
    "    for i in pos:\n",
    "        analysis=TextBlob(i)\n",
    "        pol_pos.append(analysis.sentiment.polarity)\n",
    "        avg_positive_polarity=analysis.sentiment.polarity\n",
    "    for j in neg:\n",
    "        analysis2=TextBlob(j)\n",
    "        pol_neg.append(analysis2.sentiment.polarity)\n",
    "        avg_negative_polarity=analysis2.sentiment.polarity\n",
    "    min_positive_polarity=min(pol_pos)\n",
    "    max_positive_polarity=max(pol_pos)\n",
    "    min_negative_polarity=min(pol_neg)\n",
    "    max_negative_polarity=max(pol_neg)\n",
    "    avg_positive_polarity=np.average(pol_pos)\n",
    "    avg_negative_polarity=np.average(pol_neg)\n",
    "    return global_rate_positive_words,global_rate_negative_words,avg_positive_polarity,min_positive_polarity,max_positive_polarity,avg_negative_polarity,min_negative_polarity,max_negative_polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News -  https://www.ndtv.com/world-news/north-korean-leader-kim-jong-uns-train-likely-spotted-in-resort-town-amid-health-rumours-report-2218393?News_Trending\n",
      "News -  https://www.ndtv.com/world-news/coronavirus-pandemic-all-covid19-patients-in-wuhan-discharged-says-china-2218484\n",
      "News -  https://www.ndtv.com/world-news/north-korean-leader-kim-jong-uns-train-likely-spotted-in-resort-town-amid-health-rumours-report-2218393\n",
      "News -  https://www.ndtv.com/world-news/us-president-donald-trump-russias-vladimir-putin-issue-rare-joint-statement-on-cooperation-2218385\n",
      "News -  https://www.ndtv.com/world-news/coronavirus-in-us-not-worth-time-effort-says-donald-trump-on-pressers-after-disinfectant-gaffe-2218362\n",
      "News -  https://www.ndtv.com/world-news/covid-19-death-count-global-coronavirus-death-count-crosses-2-lakhs-who-warns-over-immunity-2218355\n",
      "News -  https://www.ndtv.com/world-news/coronavirus-france-reports-369-new-covid-19-deaths-in-last-24-hours-2218327\n",
      "News -  https://www.ndtv.com/world-news/coronvirus-china-eases-restrictions-on-exports-of-some-covid-19-treatment-products-2218310\n",
      "News -  https://www.ndtv.com/world-news/coronavirus-uk-reports-813-new-covid-19-deaths-count-rises-to-20-319-2218305\n",
      "News -  https://www.ndtv.com/world-news/coronavirus-italy-9-year-old-italian-boy-lupo-daturi-creates-cerba-20-video-game-on-covid-19-2218300\n",
      "News -  https://www.ndtv.com/world-news/coronavirus-ecuador-woman-named-alba-maruri-pronounced-dead-due-to-covid-19-in-hospital-mix-up-wakes-2218291\n",
      "News -  https://www.ndtv.com/world-news/alphabets-sundar-pichais-2019-compensation-worth-281-million-2218184\n",
      "News -  https://www.ndtv.com/world-news/coronavirus-pandemic-no-evidence-that-recovered-covid-19-patients-wont-be-reinfected-who-2218169\n",
      "News -  https://www.ndtv.com/world-news/she-survived-spanish-flu-in-1918-now-at-106-she-beat-covid-19-2218072\n",
      "News -  https://www.ndtv.com/world-news/coronavirus-pandemic-covid19-global-death-count-nears-200-000-says-report-2218050\n",
      "News -  https://www.ndtv.com/world-news/page-2\n",
      "News -  https://www.ndtv.com/world-news/page-3\n",
      "News -  https://www.ndtv.com/world-news/page-4\n",
      "News -  https://www.ndtv.com/world-news/page-5\n",
      "News -  https://www.ndtv.com/world-news/page-6\n",
      "News -  https://www.ndtv.com/world-news/page-7\n",
      "News -  https://www.ndtv.com/world-news/page-8\n",
      "News -  https://www.ndtv.com/world-news/page-9\n",
      "News -  https://www.ndtv.com/world-news/page-10\n",
      "News -  https://www.ndtv.com/world-news/page-14\n"
     ]
    }
   ],
   "source": [
    "df2=[]\n",
    "for i in news:\n",
    "    print(\"News - \",i)\n",
    "    pred_info={}\n",
    "    article = Article(i, language=\"en\") # en for English \n",
    "    article.download()\n",
    "    article.parse()\n",
    "    analysis=TextBlob(article.text)\n",
    "    polarity=analysis.sentiment.polarity\n",
    "    title_analysis=TextBlob(article.title)\n",
    "    pred_info['text']=article.text\n",
    "    pred_info['n_tokens_title']=len(tokenize(article.title))\n",
    "    pred_info['n_tokens_content']=len(tokenize(article.text))\n",
    "    pred_info['n_unique_tokens']=rate_unique(article.text)\n",
    "    pred_info['n_non_stop_words']=rate_nonstop(article.text)[0]\n",
    "    pred_info['n_non_stop_unique_tokens']=rate_nonstop(article.text)[1]\n",
    "    pred_info['num_hrefs']=article.html.count(\"https://www.ndtv.com/world-news/\")\n",
    "    pred_info['num_imgs']=len(article.images)\n",
    "    pred_info['num_videos']=len(article.movies)\n",
    "    pred_info['average_token_length']=avg_token(article.text)\n",
    "    pred_info['num_keywords']=len(article.keywords)\n",
    "    \n",
    "    if \"life-style\" in article.url:\n",
    "        pred_info['data_channel_is_lifestyle']=1\n",
    "    else:\n",
    "        pred_info['data_channel_is_lifestyle']=0\n",
    "    if \"etimes\" in article.url:\n",
    "        pred_info['data_channel_is_entertainment']=1\n",
    "    else:\n",
    "        pred_info['data_channel_is_entertainment']=0\n",
    "    if \"business\" in article.url:\n",
    "        pred_info['data_channel_is_bus']=1\n",
    "    else:\n",
    "        pred_info['data_channel_is_bus']=0\n",
    "    if \"social media\" or \"facebook\" or \"whatsapp\" in article.text.lower():\n",
    "        data_channel_is_socmed=1\n",
    "        data_channel_is_tech=0\n",
    "        data_channel_is_world=0\n",
    "    else:\n",
    "        data_channel_is_socmed=0\n",
    "    if (\"technology\" or \"tech\" in article.text.lower()) or (\"technology\" or \"tech\" in article.url):\n",
    "        data_channel_is_tech=1\n",
    "        data_channel_is_socmed=0\n",
    "        data_channel_is_world=0\n",
    "    else:\n",
    "        data_channel_is_tech=0\n",
    "    if \"world\" in article.url:\n",
    "        data_channel_is_world=1\n",
    "        data_channel_is_tech=0\n",
    "        data_channel_is_socmed=0\n",
    "    else:\n",
    "        data_channel_is_world=0\n",
    "        \n",
    "    pred_info['data_channel_is_socmed']=data_channel_is_socmed\n",
    "    pred_info['data_channel_is_tech']=data_channel_is_tech\n",
    "    pred_info['data_channel_is_world']=data_channel_is_world\n",
    "    \n",
    "    try:\n",
    "        if day(i)==\"Monday\":\n",
    "            pred_info['weekday_is_monday']=1\n",
    "        else:\n",
    "            pred_info['weekday_is_monday']=0\n",
    "        if day(i)==\"Tuesday\":\n",
    "            pred_info['weekday_is_tuesday']=1\n",
    "        else:\n",
    "            pred_info['weekday_is_tuesday']=0\n",
    "        if day(i)==\"Wednesday\":\n",
    "            pred_info['weekday_is_wednesday']=1\n",
    "        else:\n",
    "            pred_info['weekday_is_wednesday']=0\n",
    "        if day(i)==\"Thursday\":\n",
    "            pred_info['weekday_is_thursday']=1\n",
    "        else:\n",
    "            pred_info['weekday_is_thursday']=0\n",
    "        if day(i)==\"Friday\":\n",
    "            pred_info['weekday_is_friday']=1\n",
    "        else:\n",
    "            pred_info['weekday_is_friday']=0\n",
    "        if day(i)==\"Saturday\":\n",
    "            pred_info['weekday_is_saturday']=1\n",
    "            pred_info['is_weekend']=1\n",
    "        else:\n",
    "            pred_info['weekday_is_saturday']=0\n",
    "        if day(i)==\"Sunday\":\n",
    "            pred_info['weekday_is_sunday']=1\n",
    "            pred_info['is_weekend']=1\n",
    "        else:\n",
    "            pred_info['weekday_is_sunday']=0\n",
    "            pred_info['is_weekend']=0\n",
    "    except:\n",
    "        continue\n",
    "    pred_info['global_subjectivity']=analysis.sentiment.subjectivity\n",
    "    pred_info['global_sentiment_polarity']=analysis.sentiment.polarity\n",
    "    pred_info['global_rate_positive_words']=rates(article.text)[0]\n",
    "    pred_info['global_rate_negative_words']=rates(article.text)[1]\n",
    "    pred_info['avg_positive_polarity']=rates(article.text)[2]\n",
    "    pred_info['min_positive_polarity']=rates(article.text)[3]\n",
    "    pred_info['max_positive_polarity']=rates(article.text)[4]\n",
    "    pred_info['avg_negative_polarity']=rates(article.text)[5]\n",
    "    pred_info['min_negative_polarity']=rates(article.text)[6]\n",
    "    pred_info['max_negative_polarity']=rates(article.text)[7]    \n",
    "    pred_info['title_subjectivity']=title_analysis.sentiment.subjectivity\n",
    "    pred_info['title_sentiment_polarity']=title_analysis.sentiment.polarity\n",
    "    df2.append(pred_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>...</th>\n",
       "      <th>global_rate_positive_words</th>\n",
       "      <th>global_rate_negative_words</th>\n",
       "      <th>avg_positive_polarity</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There have been conflicting reports about Kim ...</td>\n",
       "      <td>15</td>\n",
       "      <td>712</td>\n",
       "      <td>0.438202</td>\n",
       "      <td>0.681180</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4.480337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.283532</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.214749</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Covid -19 Cases: Wuhan in China had reported 4...</td>\n",
       "      <td>11</td>\n",
       "      <td>152</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3.960526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.283005</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.214749</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There have been conflicting reports about Kim ...</td>\n",
       "      <td>15</td>\n",
       "      <td>712</td>\n",
       "      <td>0.438202</td>\n",
       "      <td>0.681180</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4.480337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.282606</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.214749</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald Trump had hoped to travel to Moscow to ...</td>\n",
       "      <td>11</td>\n",
       "      <td>430</td>\n",
       "      <td>0.493023</td>\n",
       "      <td>0.665116</td>\n",
       "      <td>0.409302</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4.809302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.283997</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.230159</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He appeared to confirm media reports that he w...</td>\n",
       "      <td>16</td>\n",
       "      <td>444</td>\n",
       "      <td>0.560811</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>0.436937</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4.592342</td>\n",
       "      <td>...</td>\n",
       "      <td>1.055</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.303946</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.239132</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  n_tokens_title  \\\n",
       "0  There have been conflicting reports about Kim ...              15   \n",
       "1  Covid -19 Cases: Wuhan in China had reported 4...              11   \n",
       "2  There have been conflicting reports about Kim ...              15   \n",
       "3  Donald Trump had hoped to travel to Moscow to ...              11   \n",
       "4  He appeared to confirm media reports that he w...              16   \n",
       "\n",
       "   n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0               712         0.438202          0.681180   \n",
       "1               152         0.625000          0.697368   \n",
       "2               712         0.438202          0.681180   \n",
       "3               430         0.493023          0.665116   \n",
       "4               444         0.560811          0.655405   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_imgs  num_videos  \\\n",
       "0                  0.370787         15        11           0   \n",
       "1                  0.467105         15        12           0   \n",
       "2                  0.370787         15        11           0   \n",
       "3                  0.409302         15        11           0   \n",
       "4                  0.436937         15        12           0   \n",
       "\n",
       "   average_token_length  ...  global_rate_positive_words  \\\n",
       "0              4.480337  ...                       0.045   \n",
       "1              3.960526  ...                       0.375   \n",
       "2              4.480337  ...                       0.525   \n",
       "3              4.809302  ...                       0.860   \n",
       "4              4.592342  ...                       1.055   \n",
       "\n",
       "   global_rate_negative_words  avg_positive_polarity  min_positive_polarity  \\\n",
       "0                        0.09               0.283532                   0.05   \n",
       "1                        0.36               0.283005                   0.05   \n",
       "2                        0.45               0.282606                   0.05   \n",
       "3                        0.73               0.283997                   0.05   \n",
       "4                        0.79               0.303946                   0.05   \n",
       "\n",
       "   max_positive_polarity  avg_negative_polarity  min_negative_polarity  \\\n",
       "0                    0.5              -0.214749                   -0.5   \n",
       "1                    0.5              -0.214749                   -0.5   \n",
       "2                    0.5              -0.214749                   -0.5   \n",
       "3                    0.5              -0.230159                   -0.6   \n",
       "4                    0.5              -0.239132                   -0.6   \n",
       "\n",
       "   max_negative_polarity  title_subjectivity  title_sentiment_polarity  \n",
       "0                -0.0125                 1.0                      0.00  \n",
       "1                -0.0125                 0.0                      0.00  \n",
       "2                -0.0125                 1.0                      0.00  \n",
       "3                -0.0125                 0.9                      0.30  \n",
       "4                -0.0125                 0.1                     -0.15  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df=pd.DataFrame(df2)\n",
    "pred_test=pred_df.drop(['text'],axis=1)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results depicting the Likelihood of Virality of News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Virality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There have been conflicting reports about Kim ...</td>\n",
       "      <td>2909.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Covid -19 Cases: Wuhan in China had reported 4...</td>\n",
       "      <td>14581.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There have been conflicting reports about Kim ...</td>\n",
       "      <td>4129.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald Trump had hoped to travel to Moscow to ...</td>\n",
       "      <td>17232.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He appeared to confirm media reports that he w...</td>\n",
       "      <td>10315.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The World Health Organization warned on Saturd...</td>\n",
       "      <td>6250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The number of people in intensive is dropping ...</td>\n",
       "      <td>21178.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The new ruling applies to products such as cor...</td>\n",
       "      <td>10975.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The UK's official coronavirus death toll passe...</td>\n",
       "      <td>6768.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>She lost consciousness for 3 weeks and was dec...</td>\n",
       "      <td>17680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sundar Pichai was awarded $281 million in comp...</td>\n",
       "      <td>15338.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The World Health Organization (WHO) said on Sa...</td>\n",
       "      <td>18500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>COVID-19 Deaths: The pandemic has forced medic...</td>\n",
       "      <td>6730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Reports of domestic violence in London have ri...</td>\n",
       "      <td>13235.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>US Secretary of State Mike Pompeo said the COV...</td>\n",
       "      <td>10489.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Nicotine could protect people from contracting...</td>\n",
       "      <td>13580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The latest high-speed broadband technology 5G ...</td>\n",
       "      <td>15538.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>More than 180,000 people in the world have die...</td>\n",
       "      <td>13235.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>As the patients infected by the highly infecti...</td>\n",
       "      <td>13235.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>An old malaria drug touted by U.S. President D...</td>\n",
       "      <td>10489.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Even before President Donald Trump announced t...</td>\n",
       "      <td>28290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Richard Quest, CNN's top presenter and interna...</td>\n",
       "      <td>11218.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The coronavirus has killed more than 1,00,000 ...</td>\n",
       "      <td>10489.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  Virality\n",
       "0   There have been conflicting reports about Kim ...    2909.8\n",
       "1   Covid -19 Cases: Wuhan in China had reported 4...   14581.3\n",
       "2   There have been conflicting reports about Kim ...    4129.8\n",
       "3   Donald Trump had hoped to travel to Moscow to ...   17232.7\n",
       "4   He appeared to confirm media reports that he w...   10315.9\n",
       "5   The World Health Organization warned on Saturd...    6250.0\n",
       "6   The number of people in intensive is dropping ...   21178.9\n",
       "7   The new ruling applies to products such as cor...   10975.9\n",
       "8   The UK's official coronavirus death toll passe...    6768.3\n",
       "9   She lost consciousness for 3 weeks and was dec...   17680.0\n",
       "10  Sundar Pichai was awarded $281 million in comp...   15338.7\n",
       "11  The World Health Organization (WHO) said on Sa...   18500.0\n",
       "12  COVID-19 Deaths: The pandemic has forced medic...    6730.0\n",
       "13  Reports of domestic violence in London have ri...   13235.9\n",
       "14  US Secretary of State Mike Pompeo said the COV...   10489.4\n",
       "15  Nicotine could protect people from contracting...   13580.0\n",
       "16  The latest high-speed broadband technology 5G ...   15538.9\n",
       "17  More than 180,000 people in the world have die...   13235.9\n",
       "18  As the patients infected by the highly infecti...   13235.9\n",
       "19  An old malaria drug touted by U.S. President D...   10489.4\n",
       "20  Even before President Donald Trump announced t...   28290.0\n",
       "21  Richard Quest, CNN's top presenter and interna...   11218.2\n",
       "22  The coronavirus has killed more than 1,00,000 ...   10489.4"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2=pd.DataFrame(clf.predict(pred_test),pred_df['text'])\n",
    "test2.reset_index(level=0, inplace=True)\n",
    "test2 = test2.rename(index=str, columns={\"index\": \"News\", 0: \"Virality\"})\n",
    "test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hope This will fulfill you requirements. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
